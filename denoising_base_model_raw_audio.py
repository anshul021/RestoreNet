# -*- coding: utf-8 -*-
"""denoising_base_model_raw_audio.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1e1hmTe8SxBHoxyRmMJNMmUbfqcL9Kqw3
"""

from google.colab import drive
drive.mount('/content/drive')

import os, glob, random
import numpy as np
import soundfile as sf

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader

SEED = 0
random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)

NOISY_DIR = "/content/drive/MyDrive/Noisy Audio"
CLEAN_DIR = "/content/drive/MyDrive/Clean Audio"
OUT_DIR   = "/content/drive/MyDrive/Raw Audio Enhancements"

TARGET_SR = 16000
SEG_S = 2.0
SEG_SAMPLES = int(TARGET_SR * SEG_S)

BATCH_SIZE = 16
LR = 3e-4
WEIGHT_DECAY = 1e-4
EPOCHS = 8
VAL_SPLIT = 0.1
CHECKPOINT = os.path.join(OUT_DIR, "rawaudio_best.pt")
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

os.makedirs(OUT_DIR, exist_ok=True)

def read_mono_assert_sr(path, expect_sr=TARGET_SR):
    x, sr = sf.read(path)
    if sr != expect_sr:
        raise ValueError(f"{path} has sr={sr} but TARGET_SR={expect_sr}. Please resample offline.")
    if x.ndim == 2:
        x = x.mean(axis=1)
    return x.astype(np.float32)

def pair_lists(noisy_dir, clean_dir):
    noisy_files = sorted(glob.glob(os.path.join(noisy_dir, "*.wav")))
    pairs = []
    for n in noisy_files:
        name = os.path.basename(n)
        c = os.path.join(clean_dir, name)
        if os.path.exists(c):
            pairs.append((n, c))
    return pairs

class WavePairDataset(Dataset):
    def __init__(self, pairs, seg=SEG_SAMPLES, aug=True):
        self.pairs = pairs
        self.seg = seg
        self.aug = aug

    def __len__(self):
        return len(self.pairs)

    def __getitem__(self, idx):
        n_path, c_path = self.pairs[idx]
        n = read_mono_assert_sr(n_path, TARGET_SR)
        c = read_mono_assert_sr(c_path, TARGET_SR)
        L = min(len(n), len(c))
        n, c = n[:L], c[:L]

        if L < self.seg:
            pad = self.seg - L
            n = np.pad(n, (0, pad))
            c = np.pad(c, (0, pad))
            L = self.seg

        start = random.randint(0, L - self.seg)
        n = n[start:start + self.seg]
        c = c[start:start + self.seg]

        if self.aug:
            gain = 10 ** (np.random.uniform(-3, 3) / 20.0)
            n = np.clip(n * gain, -1.0, 1.0)
            c = np.clip(c * gain, -1.0, 1.0)

        return torch.from_numpy(n).unsqueeze(0), torch.from_numpy(c).unsqueeze(0)

import torch.nn.functional as F

def match_time(x, target_len):
    """Center-crop or pad a 1D feature map to target_len in time."""
    cur = x.size(-1)
    if cur == target_len:
        return x
    if cur > target_len:
        start = (cur - target_len) // 2
        return x[..., start:start + target_len]
    # pad both sides if shorter
    pad_total = target_len - cur
    pad_left = pad_total // 2
    pad_right = pad_total - pad_left
    return F.pad(x, (pad_left, pad_right))

class ConvBlock(nn.Module):
    def __init__(self, c_in, c_out, k=8, s=2, p=3):
        super().__init__()
        self.conv = nn.Conv1d(c_in, c_out, kernel_size=k, stride=s, padding=p)
        self.bn = nn.BatchNorm1d(c_out)
        self.act = nn.LeakyReLU(0.2, inplace=True)
    def forward(self, x):
        return self.act(self.bn(self.conv(x)))

class DeconvBlock(nn.Module):
    def __init__(self, c_in, c_out, k=8, s=2, p=3, op=1):
        super().__init__()
        self.tconv = nn.ConvTranspose1d(c_in, c_out, kernel_size=k, stride=s, padding=p, output_padding=op)
        self.bn = nn.BatchNorm1d(c_out)
        self.act = nn.LeakyReLU(0.2, inplace=True)
    def forward(self, x):
        return self.act(self.bn(self.tconv(x)))

class TinyDemucs1D(nn.Module):
    def __init__(self, base=64):
        super().__init__()
        self.enc1 = ConvBlock(1, base)
        self.enc2 = ConvBlock(base, base*2)
        self.enc3 = ConvBlock(base*2, base*4)
        self.enc4 = ConvBlock(base*4, base*8)

        self.bottleneck = nn.Sequential(
            nn.Conv1d(base*8, base*8, 3, 1, 1),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv1d(base*8, base*8, 3, 1, 1),
        )

        self.dec4 = DeconvBlock(base*8, base*4)
        self.dec3 = DeconvBlock(base*8, base*2)
        self.dec2 = DeconvBlock(base*4, base)
        self.dec1 = nn.ConvTranspose1d(base*2, 1, kernel_size=8, stride=2, padding=3, output_padding=1)

    def forward(self, x):
        e1 = self.enc1(x)          # [B, C1, T1]
        e2 = self.enc2(e1)         # [B, C2, T2]
        e3 = self.enc3(e2)         # [B, C3, T3]
        e4 = self.enc4(e3)         # [B, C4, T4]

        b = self.bottleneck(e4)

        d4 = self.dec4(b)                                  # ~T3
        e3m = match_time(e3, d4.size(-1))
        d3 = self.dec3(torch.cat([d4, e3m], dim=1))        # ~T2

        e2m = match_time(e2, d3.size(-1))
        d2 = self.dec2(torch.cat([d3, e2m], dim=1))        # ~T1

        e1m = match_time(e1, d2.size(-1))
        out = self.dec1(torch.cat([d2, e1m], dim=1))       # ~T0

        # final output should match input length
        out = match_time(out, x.size(-1))
        return out

def si_sdr(ref, est, eps=1e-8):
    ref = ref - ref.mean(dim=-1, keepdim=True)
    est = est - est.mean(dim=-1, keepdim=True)
    dot = torch.sum(est * ref, dim=-1, keepdim=True)
    s_ref = torch.sum(ref * ref, dim=-1, keepdim=True) + eps
    s_target = dot / s_ref * ref
    e_noise = est - s_target
    num = torch.sum(s_target**2, dim=-1) + eps
    den = torch.sum(e_noise**2, dim=-1) + eps
    return 10.0 * torch.log10(num / den)

def loss_fn(y_hat, y):
    l_sisdr = -si_sdr(y, y_hat).mean()
    l_l1 = F.l1_loss(y_hat, y)
    return l_sisdr + 0.1 * l_l1

def build_loaders():
    pairs = pair_lists(NOISY_DIR, CLEAN_DIR)
    assert len(pairs) > 0, "No wav pairs found. Check your folder paths and filenames."
    random.shuffle(pairs)
    val_n = max(1, int(len(pairs) * VAL_SPLIT))
    val_pairs = pairs[:val_n]
    train_pairs = pairs[val_n:]
    train_ds = WavePairDataset(train_pairs, seg=SEG_SAMPLES, aug=True)
    val_ds = WavePairDataset(val_pairs, seg=SEG_SAMPLES, aug=False)
    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, drop_last=True)
    val_loader   = DataLoader(val_ds, batch_size=8, shuffle=False, num_workers=2)
    return train_loader, val_loader, len(train_pairs), len(val_pairs)

def train():
    from torch.cuda.amp import autocast, GradScaler
    train_loader, val_loader, ntr, nva = build_loaders()
    print(f"Train pairs: {ntr}   Val pairs: {nva}")

    model = TinyDemucs1D(base=64).to(DEVICE)
    opt = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)
    scaler = GradScaler() if DEVICE.type == "cuda" else None

    best_sdr = -1e9
    for epoch in range(EPOCHS):
        model.train()
        losses = []
        for xb, yb in train_loader:
            xb = xb.to(DEVICE)
            yb = yb.to(DEVICE)
            opt.zero_grad(set_to_none=True)
            if scaler:
                with autocast():
                    yhat = model(xb)
                    loss = loss_fn(yhat, yb)
                scaler.scale(loss).backward()
                scaler.step(opt)
                scaler.update()
            else:
                yhat = model(xb)
                loss = loss_fn(yhat, yb)
                loss.backward()
                opt.step()
            losses.append(loss.item())
        print(f"Epoch {epoch} train loss {np.mean(losses):.4f}")

        model.eval()
        sdrs = []
        with torch.no_grad():
            for xb, yb in val_loader:
                xb = xb.to(DEVICE); yb = yb.to(DEVICE)
                yhat = model(xb)
                sdrs.append(si_sdr(yb, yhat).mean().item())
        mean_sdr = float(np.mean(sdrs)) if len(sdrs) else -1e9
        print(f"Epoch {epoch} val SI-SDR {mean_sdr:.2f} dB")

        if mean_sdr > best_sdr:
            best_sdr = mean_sdr
            torch.save({"model": model.state_dict()}, CHECKPOINT)
            print(f"Saved {CHECKPOINT}  best SI-SDR {best_sdr:.2f} dB")
    return CHECKPOINT

def enhance_raw_file(model, in_path, out_path, sr=TARGET_SR, chunk=SEG_SAMPLES, hop=None):
    if hop is None:
        hop = chunk // 2
    x, srx = sf.read(in_path)
    if srx != sr:
        raise ValueError(f"{in_path} has sr={srx} but TARGET_SR={sr}. Please resample offline.")
    if x.ndim == 2:
        x = x.mean(axis=1)
    x = x.astype(np.float32)

    T = len(x)
    out = np.zeros(T + chunk, dtype=np.float32)
    denom = np.zeros_like(out)
    win = np.hanning(chunk).astype(np.float32)

    model.eval()
    with torch.no_grad():
        for start in range(0, T, hop):
            end = min(start + chunk, T)
            buf = np.zeros(chunk, dtype=np.float32)
            buf[:end - start] = x[start:end]
            xb = torch.from_numpy(buf).unsqueeze(0).unsqueeze(0).to(DEVICE)
            yb = model(xb).squeeze().cpu().numpy()
            yb = yb * win
            out[start:start + chunk] += yb
            denom[start:start + chunk] += win

    denom = np.clip(denom, 1e-6, None)
    out = out[:T] / denom[:T]
    peak = max(1e-6, np.max(np.abs(out)))
    out = np.clip(out / peak * 0.99, -1.0, 1.0)
    sf.write(out_path, out, sr)
    print(f"Wrote {out_path}")

def write_ab(a_path, b_path, out_path, sec=1, sr=TARGET_SR):
    a, sra = sf.read(a_path)
    b, srb = sf.read(b_path)
    if sra != sr or srb != sr:
        raise ValueError("AB writer expects files at TARGET_SR.")
    if a.ndim == 2: a = a.mean(axis=1)
    if b.ndim == 2: b = b.mean(axis=1)
    L = min(len(a), len(b))
    a = a[:L]; b = b[:L]
    peak = max(np.max(np.abs(a)), np.max(np.abs(b)), 1e-6)
    a = a / peak; b = b / peak
    block = int(sr * sec)
    out = []
    t = 0
    toggle = True
    while t < L:
        out.append((a if toggle else b)[t:t+block])
        toggle = not toggle
        t += block
    out = np.concatenate(out)
    sf.write(out_path, out, sr)
    print(f"Wrote {out_path}")

if __name__ == "__main__":
    # 1) Train
    ckpt_path = train()

    # 2) Load best and enhance one demo pair
    model = TinyDemucs1D(base=64).to(DEVICE)
    state = torch.load(ckpt_path, map_location=DEVICE)
    model.load_state_dict(state["model"])
    model.eval()

    demo_name = None
    for n in sorted(glob.glob(os.path.join(NOISY_DIR, "*.wav"))):
        name = os.path.basename(n)
        if os.path.exists(os.path.join(CLEAN_DIR, name)):
            demo_name = name
            break
    if demo_name is not None:
        noisy_demo = os.path.join(NOISY_DIR, demo_name)
        out_demo = os.path.join(OUT_DIR, f"enhanced_{demo_name}")
        enhance_raw_file(model, noisy_demo, out_demo)
        ab_path = os.path.join(OUT_DIR, f"AB_{demo_name}")
        write_ab(noisy_demo, out_demo, ab_path, sec=1, sr=TARGET_SR)
        print("Listen to the AB file for a quick check.")
    else:
        print("No matching demo pair found. Enhancement step skipped.")